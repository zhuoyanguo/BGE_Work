{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuoyanguo/BGE_Work/blob/main/LinkedinScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YxNv339G6So"
      },
      "outputs": [],
      "source": [
        "# ! pip install selenium\n",
        "# ! pip install selenium.webdriver.common.by\n",
        "# ! pip install time\n",
        "# ! pip install pandas\n",
        "# ! pip install datetime\n",
        "# ! pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlPoPpLlG6Sr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcUHLiBnG6Sr",
        "outputId": "45a104ed-3da9-4fed-ec5b-5bf320c5e535"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\92767\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "import pandas as pd\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEVuS4FfG6Ss"
      },
      "source": [
        "# Step 1: Scraping information from Linkedin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mntPC6fPG6Ss"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./LinkedinInput_Sample.csv')\n",
        "profiles = df.iloc[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqiRVpmBG6Ss"
      },
      "outputs": [],
      "source": [
        "# get the wait time\n",
        "WAIT_TIME = 3\n",
        "USERNAME = \"bgecareerservices@georgetown.edu\"\n",
        "PASSWORD = \"xxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkJcHe9lG6Ss"
      },
      "outputs": [],
      "source": [
        "def login(driver, username, password):\n",
        "  # //div[@id='public_profile_contextual-sign-in']\n",
        "  driver.get(\"https://www.linkedin.com/login\")\n",
        "  # find the username input\n",
        "  username_input = driver.find_element(By.XPATH, '//input[@id=\"username\"]')\n",
        "  # send_keys() to simulate key strokes\n",
        "  username_input.send_keys(username)\n",
        "  # find the password input\n",
        "  password_input = driver.find_element(By.XPATH, '//input[@id=\"password\"]')\n",
        "  # send_keys() to simulate key strokes\n",
        "  password_input.send_keys(password)\n",
        "  # find the submit button\n",
        "  log_in_button = driver.find_element(By.XPATH, '//button[@type=\"submit\"]')\n",
        "  # click() to simulate button click\n",
        "  log_in_button.click()\n",
        "  # after login in, redirect to target profile\n",
        "  time.sleep(WAIT_TIME)\n",
        "  return driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH1E2RE3G6St"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "\n",
        "def get_name(driver):\n",
        "    try:\n",
        "        time.sleep(3)\n",
        "        name_element = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.XPATH, '//h1[contains(@class, \"break-words\")]'))\n",
        "        )\n",
        "        print(\"Found Name:\", name_element.text)\n",
        "        return name_element.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" Error getting name:\", e)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFvusZhkG6St"
      },
      "outputs": [],
      "source": [
        "def get_location(driver):\n",
        "  return driver.find_element(By.XPATH, '//span[contains(@class, \"text-body-small inline t-black--light break-words\")]').text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKh8yTrZG6St"
      },
      "outputs": [],
      "source": [
        "def get_experience(driver):\n",
        "  # find the experience section list\n",
        "  experience_section = driver.find_elements(By.XPATH, '//*[@id=\"experience\"]/parent::section//li[contains(@class,\"artdeco-list__item\")]')\n",
        "  experiences = []\n",
        "  for experience in experience_section:\n",
        "    # get the content box\n",
        "    contentbox = experience.find_element(By.XPATH, './/div[@class=\"display-flex flex-row justify-space-between\"]')\n",
        "    # Get Text from content Box\n",
        "    texts = contentbox.find_elements(By.XPATH, './/span[@aria-hidden=\"true\"]')\n",
        "    # Print Each Experience\n",
        "    experience_texts = []\n",
        "    for text in texts:\n",
        "      experience_texts.append(text.text.strip())\n",
        "    experiences.append(experience_texts)\n",
        "  return experiences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjNfwbV1G6Su"
      },
      "outputs": [],
      "source": [
        "def get_education(driver):\n",
        "  # Click Show all educations.\n",
        "  show_all_xpath = '//a[@id=\"navigation-index-see-all-education\"]'\n",
        "  # check if the show all a tag exists\n",
        "  show_all_link = driver.find_elements(By.XPATH, show_all_xpath)\n",
        "  show_all = False\n",
        "  if len(show_all_link) > 0:\n",
        "    show_all_link[0].click()\n",
        "    # flag status of show all link\n",
        "    show_all = True\n",
        "    time.sleep(WAIT_TIME)\n",
        "  # find the education section list\n",
        "  if show_all:\n",
        "    education_section = driver.find_elements(By.XPATH, '//li[contains(@class,\"artdeco-list__item\")]')\n",
        "  else:\n",
        "    education_section = driver.find_elements(By.XPATH, '//div[@id=\"education\"]/parent::section//li[contains(@class,\"artdeco-list__item\")]')\n",
        "  educations = []\n",
        "  # iterate through each education\n",
        "  for education in education_section:\n",
        "    # Get Text from education\n",
        "    texts = education.find_elements(By.XPATH, './/span[@aria-hidden=\"true\"]')\n",
        "    education_texts = []\n",
        "    for text in texts:\n",
        "      education_texts.append(text.text.strip())\n",
        "    educations.append(education_texts)\n",
        "  # navigate back to profile page if show all link exists\n",
        "  if show_all:\n",
        "    driver.back()\n",
        "    time.sleep(WAIT_TIME)\n",
        "  return educations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T3qBqZvG6Su"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "\n",
        "def get_profile(driver, profile_url):\n",
        "    driver.get(profile_url)\n",
        "    time.sleep(3)\n",
        "    profile = {\"name\": None, \"location\": None, \"experiences\": [], \"educations\": []}\n",
        "    try:\n",
        "        profile[\"name\"] = get_name(driver)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting name for {profile_url}: {e}\")\n",
        "    try:\n",
        "        profile[\"location\"] = get_location(driver)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting location for {profile_url}: {e}\")\n",
        "    try:\n",
        "        profile[\"experiences\"] = get_experience(driver)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting experience for {profile_url}: {e}\")\n",
        "    try:\n",
        "        educations = get_education(driver)\n",
        "        profile[\"educations\"] = [education[:3] for education in educations] if educations else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting education for {profile_url}: {e}\")\n",
        "    return profile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KzrtQ-RG6Su"
      },
      "outputs": [],
      "source": [
        "def get_driver():\n",
        "  driver = webdriver.Edge()\n",
        "  return driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uAJjD64G6Su"
      },
      "outputs": [],
      "source": [
        "all_profiles = []\n",
        "\n",
        "def main():\n",
        "  global all_profiles\n",
        "  driver = get_driver()\n",
        "  login(driver, USERNAME, PASSWORD)\n",
        "\n",
        "  for profile_url in profiles:\n",
        "        try:\n",
        "            profile = get_profile(driver, profile_url)\n",
        "            if profile:\n",
        "                all_profiles.append(profile)\n",
        "            else:\n",
        "                print(f\"Profile could not be retrieved: {profile_url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred with URL {profile_url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "azaI9UdnSyyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjTeNKkcG6Su",
        "outputId": "a6c00ae2-ce27-4695-cd28-319560aed53a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_profiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqjvxF4DG6Su"
      },
      "source": [
        "# Step 2: Compiling scrapped information to Excel file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(all_profiles)\n",
        "anomalous = pd.DataFrame({'anomalous': [None] * len(df)})\n",
        "df = anomalous.join(df)\n",
        "df"
      ],
      "metadata": {
        "id": "wtP1fE_yTVdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAqpLcOJG6Su",
        "outputId": "7ac12c4b-6274-4d36-b9a7-306faff24e7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['anomalous', 'name', 'location', 'experiences', 'educations'], dtype='object')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30l06z2zG6Sv",
        "outputId": "3249f4ab-9294-459b-f2d3-15d69b92c8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in DataFrame: ['anomalous', 'name', 'location', 'experiences', 'educations']\n",
            "Exact column names: [\"'anomalous'\", \"'name'\", \"'location'\", \"'experiences'\", \"'educations'\"]\n"
          ]
        }
      ],
      "source": [
        "print(\"Columns in DataFrame:\", df.columns.tolist())  # List all columns\n",
        "print(\"Exact column names:\", [repr(col) for col in df.columns])  # Show any invisible characters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWi7EHfFG6Sv"
      },
      "outputs": [],
      "source": [
        "df.rename(columns=lambda x: x.strip().lower(), inplace=True)  # Standardize column names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtHI6skhG6Sv"
      },
      "outputs": [],
      "source": [
        "# Split experiences\n",
        "\n",
        "max_experiences = df['experiences'].apply(len).max()\n",
        "\n",
        "for i in range(1, max_experiences+1):\n",
        "    df[f'experience{i}_role'] = None\n",
        "    df[f'experience{i}_company'] = None\n",
        "    df[f'experience{i}_start_date'] = None\n",
        "    df[f'experience{i}_end_date'] = None\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    for i, experience in enumerate(row['experiences']):\n",
        "        df.at[index, f'experience{i+1}_role'] = experience[0] if len(experience) > 0 else None\n",
        "        df.at[index, f'experience{i+1}_company'] = experience[1] if len(experience) > 1 else None\n",
        "\n",
        "        start_date = None\n",
        "        end_date = None\n",
        "\n",
        "        # Split duration into start and end dates if '-' is present\n",
        "        if len(experience) > 2:\n",
        "            if '-' in experience[2]:\n",
        "                parts = experience[2].split('-', 1)\n",
        "                start_date = parts[0].strip() if parts[0] else None\n",
        "                end_date = parts[1].strip() if len(parts) > 1 else None\n",
        "            else:\n",
        "                df.at[index, 'anomalous'] = 'Yes'\n",
        "        else:\n",
        "            df.at[index, 'anomalous'] = 'Yes'\n",
        "\n",
        "        # Check if end_date contains additional information and clean it up\n",
        "        if end_date and '·' in end_date:\n",
        "            end_date = end_date.split('·', 1)[0].strip()\n",
        "\n",
        "        # Replace 'present' with the latest datetime\n",
        "        if end_date and end_date.lower() == 'present':\n",
        "            end_date = datetime.datetime.now().strftime('%b %Y')\n",
        "\n",
        "        df.at[index, f'experience{i+1}_start_date'] = start_date\n",
        "        df.at[index, f'experience{i+1}_end_date'] = end_date\n",
        "\n",
        "df.drop(['experiences'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KmkyGbEG6Sv"
      },
      "outputs": [],
      "source": [
        "# Split educations\n",
        "\n",
        "max_educations = df['educations'].apply(len).max()\n",
        "\n",
        "for i in range(1, max_educations+1):\n",
        "    df[f'educations{i}_university'] = None\n",
        "    df[f'educations{i}_degree'] = None\n",
        "    df[f'educations{i}_duration'] = None\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    for i, education in enumerate(row['educations']):\n",
        "        df.at[index, f'educations{i+1}_university'] = education[0] if len(education) > 0 else None\n",
        "        df.at[index, f'educations{i+1}_degree'] = education[1] if len(education) > 1 else None\n",
        "        df.at[index, f'educations{i+1}_duration'] = education[2] if len(education) > 2 else None\n",
        "\n",
        "df.drop(['educations'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the final result\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "z0nEM4kNTRQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx9ONS3GG6Sv"
      },
      "outputs": [],
      "source": [
        "# Write to excel file\n",
        "df.to_excel(\"ScrappedOutput.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMWc_07bG6Sv"
      },
      "source": [
        "# Step3: Determin the Industry and Sector Category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dndiE2DZG6Sv"
      },
      "source": [
        "## Train the Industry model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_MyOfQWG6Sv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrjcJJYxG6Sv"
      },
      "outputs": [],
      "source": [
        "df_new = pd.read_csv('./All Programs - database.csv')\n",
        "df_cleaned = df_new[['FirstCompany','FirstPosition','FirstIndusty','FirstSector','WillingtoContact']]\n",
        "df_cleaned = df_cleaned.dropna(subset=['FirstCompany', 'FirstPosition', 'FirstIndusty','FirstSector'])\n",
        "df_cleaned = df_cleaned[df_cleaned['WillingtoContact'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0GHPUpJG6Sv"
      },
      "outputs": [],
      "source": [
        "df_cleaned['TextFeatures'] = df_cleaned['FirstCompany'] + ' ' + df_cleaned['FirstPosition']\n",
        "X = df_cleaned['TextFeatures']\n",
        "y = df_cleaned['FirstIndusty']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZil2rSUG6Sv",
        "outputId": "dbca5338-5780-4e79-de2f-c817e0eb6add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after processing: 0.670995670995671\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', RandomForestClassifier()),\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "y_pred_series = pd.Series(y_pred, index=X_test.index)\n",
        "\n",
        "y_pred_corrected = pd.Series(y_pred, index=X_test.index)\n",
        "\n",
        "accuracy_corrected = accuracy_score(y_test, y_pred_corrected)\n",
        "print(f'Accuracy after processing: {accuracy_corrected}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGsDQkaLG6Sv"
      },
      "source": [
        "## Make the Industry Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-MiGeTxG6Sw"
      },
      "outputs": [],
      "source": [
        "for i in range(1, max_experiences + 1):\n",
        "    role_col = f'experience{i}_role'\n",
        "    company_col = f'experience{i}_company'\n",
        "    prediction_col = f'experience{i}_industry_prediction'\n",
        "\n",
        "    # Find the index of the company column to insert the prediction column after it\n",
        "    company_col_index = df.columns.get_loc(company_col)\n",
        "\n",
        "    # Combine role and company with whitespace removed; treat both empty as \"Unknown\"\n",
        "    combined_features = df.apply(\n",
        "        lambda row: f\"{str(row[role_col]).strip() if pd.notnull(row[role_col]) else ''} \"\n",
        "                    f\"{str(row[company_col]).strip() if pd.notnull(row[company_col]) else ''}\".strip(),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Generate predictions only if role or company has value\n",
        "    predictions = [\n",
        "        None if feature == '' else pipeline.predict([feature])[0]\n",
        "        for feature in combined_features\n",
        "    ]\n",
        "\n",
        "    # Drop existing prediction column if it exists\n",
        "    if prediction_col in df.columns:\n",
        "        df.drop(columns=[prediction_col], inplace=True)\n",
        "\n",
        "    # Insert predictions into the dataframe right after the company column\n",
        "    df.insert(company_col_index + 1, prediction_col, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glEEbG_ZG6Sw"
      },
      "outputs": [],
      "source": [
        "df.to_excel(\"LinkedinOutput_industrypredictoin.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnhYgWAuG6Sw"
      },
      "source": [
        "## Train the Sector model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK07nCd3G6Sw"
      },
      "outputs": [],
      "source": [
        "df_new = pd.read_csv('./All Programs - database.csv')\n",
        "df_cleaned = df_new[['FirstCompany','FirstPosition','FirstIndusty','FirstSector','WillingtoContact']]\n",
        "df_cleaned = df_cleaned.dropna(subset=['FirstCompany', 'FirstPosition', 'FirstIndusty','FirstSector'])\n",
        "df_cleaned = df_cleaned[df_cleaned['WillingtoContact'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2msvmUkG6S0"
      },
      "outputs": [],
      "source": [
        "df_cleaned['TextFeatures'] = df_cleaned['FirstCompany'] + ' ' + df_cleaned['FirstPosition']\n",
        "X = df_cleaned['TextFeatures']\n",
        "y = df_cleaned['FirstSector']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0s8_WfNG6S0",
        "outputId": "6dbc48ea-7707-434f-c237-1304abb90ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy after processing: 0.7056277056277056\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', RandomForestClassifier()),\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "y_pred_series = pd.Series(y_pred, index=X_test.index)\n",
        "\n",
        "y_pred_corrected = pd.Series(y_pred, index=X_test.index)\n",
        "\n",
        "y_pred_corrected = y_pred_corrected.index.map(\n",
        "    lambda idx: \"Research\" if \"research\" in X_test[idx].lower() or \"fellow\" in X_test[idx].lower() else (\n",
        "                \"Education\" if \"tutor\" in X_test[idx].lower() or \"professor\" in X_test[idx].lower() else (\n",
        "                \"Technology\" if \"software\" in X_test[idx].lower() or\n",
        "                                (\"programmer\" in X_test[idx].lower() and not any(bio_term in X_test[idx].lower() for bio_term in [\"Bioinformatics\", \"Bioinformatic\",\"Biostatistical \"])) else (\n",
        "                \"Medicine\" if \"doctor\" in X_test[idx].lower() else y_pred_corrected[idx]\n",
        "                )))\n",
        ")\n",
        "\n",
        "accuracy_corrected = accuracy_score(y_test, y_pred_corrected)\n",
        "print(f'Accuracy after processing: {accuracy_corrected}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPrSESJG6S0"
      },
      "source": [
        "## Make the Sector prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4mV9gd0G6S0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('./LinkedinOutput_industrypredictoin.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdBCXXRXG6S0"
      },
      "outputs": [],
      "source": [
        "for i in range(1, max_experiences + 1):\n",
        "    role_col = f'experience{i}_role'\n",
        "    company_col = f'experience{i}_company'\n",
        "    prediction_col = f'experience{i}_sector_prediction'\n",
        "\n",
        "    # Find the index of the company column to insert the prediction column after it\n",
        "    company_col_index = df.columns.get_loc(company_col)\n",
        "\n",
        "    # Combine role and company columns with proper handling of missing values\n",
        "    combined_features = df.apply(\n",
        "        lambda row: f\"{str(row[role_col]).strip() if pd.notnull(row[role_col]) else ''} \"\n",
        "                    f\"{str(row[company_col]).strip() if pd.notnull(row[company_col]) else ''}\".strip(),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Generate predictions: leave blank (None) if both role and company are empty\n",
        "    predictions = [\n",
        "        None if feature == '' else pipeline.predict([feature])[0]\n",
        "        for feature in combined_features\n",
        "    ]\n",
        "\n",
        "    # Drop existing prediction column if it exists\n",
        "    if prediction_col in df.columns:\n",
        "        df.drop(columns=[prediction_col], inplace=True)\n",
        "\n",
        "    # Insert predictions into the dataframe right after the company column (+2 offset for safer placement)\n",
        "    df.insert(company_col_index + 2, prediction_col, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_niNnPgjG6S0"
      },
      "outputs": [],
      "source": [
        "df.to_excel(\"LinkedinOutput_Finalized.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}